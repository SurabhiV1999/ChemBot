# ChemBot Environment Configuration
# Copy this file to .env and fill in your actual values
# Command: cp env.example .env

# ============================================
# APPLICATION SETTINGS
# ============================================
APP_NAME="ChemBot API"
APP_VERSION="1.0.0"
DEBUG=True
HOST="0.0.0.0"
PORT=8000

# ============================================
# DATABASE CONFIGURATION
# ============================================
# MongoDB Connection
MONGODB_URL="mongodb://localhost:27017"
MONGODB_DB_NAME="chembot"

# Redis Cache
REDIS_HOST="localhost"
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=""
REDIS_CACHE_ENABLED=True
REDIS_CACHE_TTL=604800  # 7 days in seconds

# ============================================
# SECURITY & AUTHENTICATION
# ============================================
# Generate secure random keys using:
# python -c "import secrets; print(secrets.token_urlsafe(32))"

SECRET_KEY="your-secret-key-change-this-in-production-min-32-chars"
ALGORITHM="HS256"
ACCESS_TOKEN_EXPIRE_MINUTES=10080  # 7 days

JWT_SECRET_KEY="your-jwt-secret-key-change-in-production-min-32-chars"
JWT_ALGORITHM="HS256"
JWT_EXPIRATION_HOURS=168  # 7 days

# ============================================
# LLM CONFIGURATION (Choose one provider)
# ============================================
# OpenAI (Recommended)
OPENAI_API_KEY="sk-your-openai-api-key-here"
LLM_MODEL="gpt-3.5-turbo"  # Options: gpt-3.5-turbo, gpt-4, gpt-4-turbo

# OR Anthropic Claude
# ANTHROPIC_API_KEY="sk-ant-your-anthropic-key-here"
# LLM_MODEL="claude-3-sonnet-20240229"

# OR Google Gemini
# GEMINI_API_KEY="your-gemini-api-key-here"
# LLM_MODEL="gemini-pro"

# LLM Settings
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2000

# ============================================
# EMBEDDINGS CONFIGURATION
# ============================================
EMBEDDING_MODEL="text-embedding-3-small"  # OpenAI embedding model
EMBEDDING_DIMENSION=1536

# ============================================
# VECTOR DATABASE (Choose one)
# ============================================
VECTOR_DB_PROVIDER="pinecone"  # Options: pinecone, weaviate

# Pinecone Configuration (Serverless)
PINECONE_API_KEY="your-pinecone-api-key-here"
# PINECONE_ENVIRONMENT is NOT required for Pinecone v3+ serverless (uses us-east-1 by default)
PINECONE_INDEX_NAME="chembot"

# OR Weaviate Configuration
# WEAVIATE_URL="http://localhost:8080"
# WEAVIATE_API_KEY="your-weaviate-api-key-here"  # Optional for cloud

# ============================================
# RAG PIPELINE CONFIGURATION
# ============================================
# Chunking Strategy
CHUNKING_STRATEGY="semantic"  # Options: heuristic, semantic, intelligent
CHUNK_SIZE=800
CHUNK_OVERLAP=100
MIN_CHUNK_SIZE=100
MAX_CHUNK_SIZE=2000

# Document Processing
MAX_WORKERS=4

# Query Engine
TOP_K_RESULTS=5

# ============================================
# CHATBOT CONFIGURATION
# ============================================
ENABLE_STREAMING=True
PROMPTS_FILE="src/backend/prompts.yaml"
CONVERSATION_HISTORY_LENGTH=5
ENABLE_QUERY_CLASSIFICATION=True

# ============================================
# RATE LIMITING
# ============================================
LLM_MAX_CONCURRENT_REQUESTS=5
LLM_MAX_RETRIES=3
LLM_RETRY_DELAY=1.0
LLM_RETRY_BACKOFF=2.0

# ============================================
# FILE UPLOAD
# ============================================
UPLOAD_DIR="uploads"
MAX_UPLOAD_SIZE=52428800  # 50MB in bytes

# ============================================
# CORS CONFIGURATION
# ============================================
# CORS_ORIGINS is handled in config.py as a list

# ============================================
# FRONTEND CONFIGURATION
# ============================================
# For frontend .env file:
# VITE_API_BASE_URL=http://localhost:8000/api

# ============================================
# MINIMUM REQUIRED CONFIGURATION
# ============================================
# To get started quickly, you only need these:
# 1. OPENAI_API_KEY
# 2. PINECONE_API_KEY
# 3. PINECONE_ENVIRONMENT
# 4. JWT_SECRET_KEY (generate with: python -c "import secrets; print(secrets.token_urlsafe(32))")
# 5. SECRET_KEY (generate with: python -c "import secrets; print(secrets.token_urlsafe(32))")

# ============================================
# QUICK SETUP GUIDE
# ============================================
# 1. Copy this file:
#    cp env.example .env
#
# 2. Get OpenAI API Key:
#    Visit: https://platform.openai.com/api-keys
#
# 3. Get Pinecone API Key:
#    Visit: https://www.pinecone.io/
#    Create index named "chembot"
#
# 4. Generate secret keys:
#    python -c "import secrets; print(secrets.token_urlsafe(32))"
#
# 5. Replace the values in .env file
#
# 6. Start the application:
#    uv run uvicorn src.backend.main:app --reload

# ============================================
# PRODUCTION SETTINGS
# ============================================
# For production deployment, change these:
# DEBUG=False
# MONGODB_URL="mongodb://username:password@production-host:27017"
# REDIS_HOST="production-redis-host"
# REDIS_PASSWORD="your-secure-redis-password"
# Use strong random values for SECRET_KEY and JWT_SECRET_KEY

# ============================================
# NOTES
# ============================================
# - Never commit the .env file to version control (it's in .gitignore)
# - Default LLM is gpt-3.5-turbo for speed and cost efficiency
# - Redis caching can save 60-80% on LLM API costs
# - Semantic chunking works best for structured documents
# - Rate limiting prevents API overload with 5 concurrent requests max

